{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Modeling Text (50 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF\n",
    "\n",
    "\n",
    "First, you will need to download the review.json file from the Resources tab on Piazza, a collection of about 7,000 Yelp reviews we sampled from the [Yelp Dataset Challenge](https://www.yelp.com/dataset_challenge). You'll see that each line corresponds to a review on a particular business. Each review has a unique \"ID\" and the text content is in the \"review\" field. You need to load the json file first. We already have done some basic preprocessing on the reviews, so you can just tokenize each review using whitespace."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here you can treat each review as a document. Given a query, you need to calculate its TF-IDF score in each review.  For this homework, we will define the TF-IDF as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`TF = number of times word occurs in a document`\n",
    "\n",
    "`IDF = log(total number of documents / number of documents containing the word)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A) Ranking with simple sums of TF-IDF scores\n",
    "\n",
    "To start out with, for a multi-word query, we will rank documents by a simple sum of the TF-IDF scores for the query terms in the document. \n",
    "\n",
    "Please calculate this TF-IDF sum score for queries `\"best bbq\"` and `\"kid fun and food\"`. You need to report the Top-10 reviews with highest TF-IDF scores for each query. Your output should look like this:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Query \"best bbq\"\n",
    "\n",
    "Rank Review_ID score\n",
    "\n",
    "1 dhskfhjskfhs 0.55555\n",
    "\n",
    "...\n",
    "\n",
    "\n",
    "\n",
    "Query \"kid fun and food\"\n",
    "\n",
    "Rank Review_ID score\n",
    "\n",
    "1 dhskfhjskfhs 0.55555\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import math\n",
    "def termFrequency(term, doc):  \n",
    "    TermList_doc = doc.split()  \n",
    "    TF_in_doc= TermList_doc.count(term.lower())   \n",
    "    return TF_in_doc \n",
    "\n",
    "def inverseDocumentFrequency(term, allDocs): \n",
    "    DF = 0 \n",
    "    for doc in range(len(allDocs)): \n",
    "        if term in allDocs[doc].split(): \n",
    "            DF += 1\n",
    "    if DF > 0: \n",
    "        total_num_docs = len(allDocs)  \n",
    "        idf_val = math.log(float(total_num_docs) / DF) \n",
    "        return idf_val \n",
    "    else: \n",
    "        return 0\n",
    "    \n",
    "def tf_idf_score(term, doc) :\n",
    "    return termFrequency(term, doc)* inverseDocumentFrequency(term,doc)\n",
    "\n",
    "data = pd.read_json('review.json', lines=True)\n",
    "idvec=data['id']\n",
    "reviews=data['review']\n",
    "\n",
    "def tfidfvec(string):\n",
    "    termlist=string.lower().split()\n",
    "    idf_dic={}\n",
    "    tf_idf_dic_lis=np.zeros((len(reviews),2))\n",
    "    for term in termlist:\n",
    "        idf_dic[term]=inverseDocumentFrequency(term,reviews)\n",
    "    for doc in range(len(reviews)):\n",
    "        for term in termlist:\n",
    "            tf_idf_dic_lis[doc][0]=doc\n",
    "            tf_idf_dic_lis[doc][1]=((termFrequency(term,reviews[doc]))*idf_dic[term])+tf_idf_dic_lis[doc][1]\n",
    "    return tf_idf_dic_lis\n",
    "def top10(query):\n",
    "    tf_idf_dic_lis=tfidfvec(query)\n",
    "    tf_idf_dic_lis=sorted(tf_idf_dic_lis,key=lambda x: x[1],reverse=True)\n",
    "    print(\"Rank    Review_ID        score\\n\")\n",
    "    for rank in range(10):\n",
    "        print('%d %s %0.2f' % (rank+1,idvec[tf_idf_dic_lis[rank][0]],tf_idf_dic_lis[rank][1]))\n",
    "  #  print(\"\\n\\nThe Best Match:\"+reviews[tf_idf_dic_lis[0][0]])\n",
    "\n",
    "            \n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank    Review_ID        score\n",
      "\n",
      "1 YbQvHNrjZJ38mnh5rLuq7w 26.32\n",
      "2 P31kXP4oan6ZQm69TN6tIA 21.93\n",
      "3 x5esEK6J9XkA_vbvVbG8Gg 19.51\n",
      "4 mWs26TrBM7ogwCM9UfVJFg 17.55\n",
      "5 NCfX4AxDvQ3QRyXKtmhVwQ 17.55\n",
      "6 e5INq6DAZn2zMHicKQl07Q 15.12\n",
      "7 4WTG1-9mw8YHEyaTu8dQww 15.12\n",
      "8 x3n_l3GhBx78y6jWX4fStg 13.72\n",
      "9 Wp8jYXL1DQrgrnZIFmufFg 13.16\n",
      "10 jrEx93eYKIjCW2nrkwjZpQ 13.16\n"
     ]
    }
   ],
   "source": [
    "# Show us the result for \"best bbq\"\n",
    "top10(\"best bbq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank    Review_ID        score\n",
      "\n",
      "1 7o_hciiXEMNQkXfVl0F0XQ 22.20\n",
      "2 JKLUXUovJCU6kbcdin74NQ 20.01\n",
      "3 IA8TOfGKI-Il-70BsB6HgA 18.73\n",
      "4 Kytq1NbFIDDCXUculSqT8g 16.79\n",
      "5 MF6rPRx9jz-g8S5P_ZIdyg 16.30\n",
      "6 bjoedmJ4_DZP5JnfXVaC-w 15.72\n",
      "7 I00B-QG5uTKvwCK7x9ejeA 15.66\n",
      "8 BVGRJgDJGEhSfgIPCan7vQ 15.48\n",
      "9 wMB3cI3-xhxM_BpmppY9RQ 14.79\n",
      "10 vTGDEQGp6EPlwdMJUnTb7A 13.91\n"
     ]
    }
   ],
   "source": [
    "# Show us the result for \"kid fun and food\"\n",
    "\n",
    "top10(\"kid fun and food\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B) Ranking with TF-IDF + Cosine\n",
    "\n",
    "Instead of using the sum of TF-IDF scores, let's try the classic cosine approach for ranking. You should still use the TF-IDF scores to weigh each term, but now use the cosine between the query vector and the document vector to assign a similarity score. You can try the same two queries as before and report the results. (Top-10 reviews which are similar to the query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "\n",
    "def l2_norm(a):\n",
    "    return math.sqrt(np.dot(a, a))\n",
    "def cosine_similarity(a, b, b_deno):\n",
    "    return b / (a* l2_norm(b_deno))\n",
    "# def query_unit_vector(query):\n",
    "#     return (len(query.split()))\n",
    "\n",
    "# def doc_vec(doc):\n",
    "#     string=reviews[doc]\n",
    "#     idf_dic={}\n",
    "#     b=0\n",
    "#     length=len(string.split())\n",
    "#     doc_vec=np.zeros((length))\n",
    "#     for idx,term in enumerate(string.split()):\n",
    "#             if term not in doc_vec_dic[doc].keys():\n",
    "#                 if term not in idf_dic.keys():\n",
    "#                     idf_dic[term]=inverseDocumentFrequency(term,reviews)\n",
    "#                 doc_vec[idx]=((termFrequency(term,string))*idf_dic[term])\n",
    "#                 doc_vec_dic[doc][term]=doc_vec[idx]\n",
    "#     return doc_vec\n",
    "\n",
    "# for doc in range(length):\n",
    "#         d_deno.append(doc_vec(doc))\n",
    "df_dic={}   \n",
    "idf_dic={}\n",
    "length=len(reviews)\n",
    "doc_vec_dic=[dict() for x in range(length)]  \n",
    "tf_doc_dic=[dict() for x in range(length)] \n",
    "for doc in range(length):\n",
    "        wordlist=reviews[doc].split()\n",
    "        unique_words=set(wordlist)\n",
    "        for w in unique_words:\n",
    "            if w not in df_dic:\n",
    "                df_dic[w]=0\n",
    "            df_dic[w]=df_dic[w]+1\n",
    "            tf_doc_dic[doc][w]=(wordlist.count(w))\n",
    "for term in df_dic:\n",
    "    idf_dic[term] = math.log(float(length) / df_dic[term]) \n",
    "final_weights=[]\n",
    "for doc in range(length):\n",
    "    sum=0\n",
    "    for idx,w in enumerate(tf_doc_dic[doc]):\n",
    "        doc_vec_dic[doc][w]=(tf_doc_dic[doc][w]*idf_dic[w])\n",
    "        sum=sum+doc_vec_dic[doc][w]**2\n",
    "    final_weights.append(math.sqrt(sum))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank    Review_ID        score\n",
      "\n",
      "1 6wRJtHhvQsS6vOse466_3w 0.53\n",
      "2 x5esEK6J9XkA_vbvVbG8Gg 0.44\n",
      "3 eAXFFP3GxUfGjQlAZDB_CQ 0.42\n",
      "4 7LaBODDEaUNRpLPDG_bKtQ 0.40\n",
      "5 P31kXP4oan6ZQm69TN6tIA 0.36\n",
      "6 ZAn6zB6VOCsJ1OsGRv-NVA 0.35\n",
      "7 8p-KEtrrTmLv-o1mKpUy1A 0.34\n",
      "8 RHWT1KVeIw2FT7i5BP_TVw 0.32\n",
      "9 _fNfowXaxXcYChKukMrYeg 0.31\n",
      "10 AEiNkWY-4ggToDeMTd8l1w 0.30\n"
     ]
    }
   ],
   "source": [
    "# Show us the result for \"best bbq\"\n",
    "def doc_num(doc,query):\n",
    "    string=reviews[doc]\n",
    "    termlist=query.split()\n",
    "    b=0\n",
    "    for term in termlist:\n",
    "        if term in doc_vec_dic[doc]:\n",
    "            b=b+doc_vec_dic[doc][term]\n",
    "    return b\n",
    "def similarity(q):\n",
    "    termlist=q.split()\n",
    "    q_len=len(termlist)\n",
    "    a=math.sqrt(q_len)\n",
    "    cosinevalues=np.zeros((length,2))\n",
    "    for doc in range(length):\n",
    "        b=final_weights[doc]\n",
    "        c=doc_num(doc,q)\n",
    "        cosinevalues[doc][0]=doc\n",
    "        cosinevalues[doc][1]=(c/(a*b))#c=doc_num,a=q_den,b=doc_den\n",
    "    cosinevalues=sorted(cosinevalues,key=lambda x: x[1],reverse=True)\n",
    "    print(\"Rank    Review_ID        score\\n\")\n",
    "    for rank in range(10):\n",
    "        print('%d %s %0.2f' % (rank+1,idvec[cosinevalues[rank][0]],cosinevalues[rank][1]))\n",
    "similarity(\"best bbq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank    Review_ID        score\n",
      "\n",
      "1 IUME6cWFSwH1mSh_1_U81g 0.39\n",
      "2 ag1fnnEmc2yernTW2ur2eg 0.32\n",
      "3 OExraycGW4VxL0Xth1xZ4w 0.28\n",
      "4 37RfMeDMo8QEVAF8yT31Ww 0.20\n",
      "5 x72i0s6q84ouimza6Y3HSQ 0.20\n",
      "6 6xdziQ46TZWKBpKQPNCSGw 0.19\n",
      "7 Pp0h1AxxHpTU-ylBt2mldQ 0.17\n",
      "8 1HshwJX7afs-CKdczFbI5g 0.17\n",
      "9 a2xfP0RpJAhioxUUHCX6QQ 0.17\n",
      "10 _AXfMxnvGx6a4L_ZgPCMKA 0.17\n"
     ]
    }
   ],
   "source": [
    "# Show us the result for \"kid fun and food\"\n",
    "similarity(\"kid fun and food\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C) Ranking with BM25\n",
    "\n",
    "Finally, let's try the BM25 approach for ranking. Refer to [https://en.wikipedia.org/wiki/Okapi_BM25](https://en.wikipedia.org/wiki/Okapi_BM25) for the specific formula. You should choose k_1 = 1.2 and b = 0.75. You need to report the Top-10 reviews with highest BM25 scores for each query.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "def bm25(query):\n",
    "    k_1 = 1.2 \n",
    "    b=0.75\n",
    "    termlist=query.split()\n",
    "    bm25ranks=np.zeros((length,2))\n",
    "    sum=0\n",
    "    for doc in range(length):\n",
    "        sum=len(reviews[doc].split())+sum\n",
    "    avgdl=sum/length\n",
    "    for doc in range(length):\n",
    "        doclen=len(reviews[doc].split())\n",
    "        temp=0\n",
    "        for term in termlist:\n",
    "            f_in_doc=0\n",
    "            if term in tf_doc_dic[doc]:\n",
    "                f_in_doc=tf_doc_dic[doc][term]\n",
    "            temp=(idf_dic[term]*f_in_doc*(k_1+1)/(f_in_doc+(k_1*(1-b+b*(doclen/avgdl)))))+temp\n",
    "        bm25ranks[doc][0]=doc\n",
    "        bm25ranks[doc][1]=temp          \n",
    "    bm25ranks=sorted(bm25ranks,key=lambda x: x[1],reverse=True)\n",
    "    print(\"Rank    Review_ID        score\\n\")\n",
    "    for rank in range(10):\n",
    "        print('%d %s %0.2f' % (rank+1,idvec[bm25ranks[rank][0]],bm25ranks[rank][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank    Review_ID        score\n",
      "\n",
      "1 x5esEK6J9XkA_vbvVbG8Gg 9.72\n",
      "2 xpm6TgDiHaQdEDlErFsqvQ 9.42\n",
      "3 4WTG1-9mw8YHEyaTu8dQww 8.96\n",
      "4 e5INq6DAZn2zMHicKQl07Q 8.59\n",
      "5 GASAd_gPBY_eWIL9XJwuNA 7.98\n",
      "6 P31kXP4oan6ZQm69TN6tIA 7.88\n",
      "7 8p-KEtrrTmLv-o1mKpUy1A 7.62\n",
      "8 HzNxErSCQ2FYfPCbyfHrSQ 7.44\n",
      "9 -RApX_RMzJLnpommDpQfKQ 7.38\n",
      "10 1tJ_iJX_KZ3zM_9_GRaGTg 7.19\n"
     ]
    }
   ],
   "source": [
    "# Show us the result for \"best bbq\"\n",
    "\n",
    "bm25(\"best bbq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank    Review_ID        score\n",
      "\n",
      "1 kDwMMrSiB_AlV0erhVigFg 7.92\n",
      "2 6xdziQ46TZWKBpKQPNCSGw 7.03\n",
      "3 UMqvuRtTxJFuWbgT6qO9cg 6.96\n",
      "4 TVq6HhhJizKM1mReF9hvJQ 6.94\n",
      "5 OExraycGW4VxL0Xth1xZ4w 6.94\n",
      "6 nuKIKXuQ51eRywuCcoX3fQ 6.87\n",
      "7 k7HxGMgabFxDUi2XWZ_hOg 6.86\n",
      "8 JKLUXUovJCU6kbcdin74NQ 6.82\n",
      "9 EDQzFQ7yYbRVUWCNA4rTOQ 6.80\n",
      "10 BLQYsPFFAezpbbF-1dzD4Q 6.78\n"
     ]
    }
   ],
   "source": [
    "# Show us the result for \"kid fun and food\"\n",
    "bm25(\"kid fun and food\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Briefly discuss the differences you see between the three methods. Is there one you prefer? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The TF-IDF method is a basic term frequency dependant method that just counts the frequency fo the query terms in the documents and multiplies them with the global IDF value. Thus the document gets ranked solely on the term frequencies in the document. The TF-IDF cosine method, however, evaluates the compactness of the document as it takes into account the fraction of the document that comprises of the query terms. Finally, the BM25 document gives us a global relevance to all the documents available as it incorporates the average document length of all the documents. It helps us comapare the documents wrt more/less relevant documents in the list.\n",
    "\n",
    "Hence, I prefer BM25 as it gives us a global score by factoring in a global variable avgdl or average document length, that makes the ranking much more comparative and concise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Link Analysis (40 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Trust Graph\n",
    "\n",
    "\n",
    "In this part, we're going to adapt the classic HITS approach to allow us to find not the most authoritative web pages, but rather to find the most trustworthy users. [Epinions.com](https://snap.stanford.edu/data/soc-Epinions1.html) is a general consumer review site with a who-trust-whom online social network. Members of the site can decide whether to ''trust'' each other. All the trust relationships interact and form the Web of Trust which is then combined with review ratings to determine which reviews are shown to the user. (Refer to: Richardson, Matthew, Rakesh Agrawal, and Pedro Domingos. \"Trust management for the semantic web.\" International semantic Web conference. Springer, Berlin, Heidelberg, 2003.)\n",
    "\n",
    "So, instead of viewing the world as web pages with hyperlinks (where pages = nodes, hyperlinks = edges), we're going to construct a graph of Epinions users and their \"trust\" on other users (so user = node, trust behavior = edge). Over this Epinions-user graph, we can apply the HITS approach to order the users by their hub-ness and their authority-ness.\n",
    "\n",
    "You need to download the *Epinions_trust.txt* file from the Resources tab on Piazza. Each line represents the trust relationship between two users. Here is a toy example. Suppose you are given the following four lines:\n",
    "\n",
    "* diane trust bob\n",
    "* charlie trust bob \n",
    "* charlie trust alice\n",
    "* bob trust charlie\n",
    "\n",
    "The \"trust\" between each user pair denotes a directed edge between two nodes. E.g., the \"diane\" node has a directed edge to the \"bob\" node (as indicated by the first line). \n",
    "\n",
    "You should build a graph by parsing the data in the file we provide called *Epinions_trust.txt*. (Note: The edges are binary and directed.)\n",
    "\n",
    "**Notes:**\n",
    "\n",
    "* The edges are binary and directed.\n",
    "* User can't trust himself/herself.\n",
    "* Later you will need to implement the HITS algorithm on the graph you build here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Nodes: 658 \n",
      "Number of Edges: 6392 \n"
     ]
    }
   ],
   "source": [
    "# Here define your function for building the graph \n",
    "# by parsing the input file \n",
    "# Insert as many cells as you want\n",
    "np.set_printoptions(threshold=np.inf)\n",
    "trust=[]\n",
    "with open(\"Epinions_trust.txt\", \"r\") as f:\n",
    "    for line in f:\n",
    "        string=line\n",
    "        trust.append(string.split())\n",
    "from collections import defaultdict\n",
    "outlink = defaultdict(list)\n",
    "inlink = defaultdict(list)\n",
    "allnames=[]\n",
    "for relation in range(len(trust)):\n",
    "    if(trust[relation][0] != trust[relation][2]):\n",
    "        allnames.append(trust[relation][0])\n",
    "        allnames.append(trust[relation][2])\n",
    "allnames=list(set(allnames))#List of all the unique names, id=allnames.index(name)\n",
    "for relation in range(len(trust)):\n",
    "    outlink[allnames.index(trust[relation][0])].append(allnames.index(trust[relation][2]))\n",
    "    inlink[allnames.index(trust[relation][2])].append(allnames.index(trust[relation][0]))\n",
    "length=len(allnames)\n",
    "graph=np.zeros((length,length))\n",
    "for idx,name in enumerate(allnames):\n",
    "    for related in outlink[name]:\n",
    "        graph[idx][allnames.index(related)]=1\n",
    "print(\"Number of Nodes: %d \"% len(allnames))\n",
    "print(\"Number of Edges: %d \" %len(trust))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please show us the size of the graph, i.e., the number of nodes and edges\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HITS Implementation\n",
    "\n",
    "Your program will return the top 10 users with highest hub and authority scores. The **output** should be like:\n",
    "\n",
    "Hub Scores\n",
    "\n",
    "* user1 - score1\n",
    "* user2 - score2\n",
    "* ...\n",
    "* user10 - score10\n",
    "\n",
    "Authority Scores\n",
    "\n",
    "* user1 - score1\n",
    "* user2 - score2\n",
    "* ...\n",
    "* user10 - score10\n",
    "\n",
    "You should follow these **rules**:\n",
    "\n",
    "* Assume all nodes start out with equal scores.\n",
    "* It is up to you to decide when to terminate the HITS calculation.\n",
    "* There are HITS implementations out there on the web. However, remember, your code should be **your own**.\n",
    "\n",
    "\n",
    "**Hints**:\n",
    "* If you're using the matrix style approach, you should use [numpy.matrix](https://docs.scipy.org/doc/numpy/reference/generated/numpy.matrix.html).\n",
    "* Scipy is built on top of Numpy and has support for sparse matrices. You most likely will not need to use Scipy unless you'd like to try out their sparse matrices.\n",
    "* If you choose to use Numpy (and Scipy), please make sure your Anaconda environment include their latest versions.\n",
    "* Test your parsing and HITS calculations using a handful of trust relationships, before moving on to the entire file we provide.\n",
    "* We will evaluate the user ranks you provide as well as the quality of your code. So make sure that your code is clear and readable.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(658, 658)\n",
      "\n",
      "Hub Scores:\n",
      "Rank  Name  score\n",
      "\n",
      "1 charles-0.18\n",
      "2 teanna3-0.18\n",
      "3 JediKermit-0.16\n",
      "4 melissasrn-0.15\n",
      "5 KCFemme-0.15\n",
      "6 missi31-0.14\n",
      "7 jeanniekerns-0.14\n",
      "8 jag2112-0.14\n",
      "9 mrssmoopy-0.14\n",
      "10 briandalsmom-0.14\n",
      "\n",
      "Authority Scores:\n",
      "Rank  Name  score\n",
      "\n",
      "1 melissasrn-0.01\n",
      "2 shantel575-0.01\n",
      "3 surferdude7-0.01\n",
      "4 sblaydes-0.01\n",
      "5 tiffer0220-0.01\n",
      "6 opinionated3-0.01\n",
      "7 patch3boys-0.01\n",
      "8 merlot-0.01\n",
      "9 pogomom-0.01\n",
      "10 chrisceb-0.00\n"
     ]
    }
   ],
   "source": [
    "# Call your function to print out the size of the graph\n",
    "print(graph.shape)\n",
    "import math\n",
    "# How you maintain the graph is totally up to you\n",
    "hubs=np.ones((length))\n",
    "auth=np.ones((length))\n",
    "for i in range(5):\n",
    "    norm=0\n",
    "    for user in range(length):\n",
    "        hubsum=0\n",
    "        for conn in outlink[user]:\n",
    "            hubsum=auth[conn]+hubsum\n",
    "        hubs[user]=hubsum\n",
    "        norm+=hubsum**2\n",
    "    norm=math.sqrt(norm)\n",
    "    for user in range(length):\n",
    "        hubs[user]=hubs[user]/norm\n",
    "    norm=0\n",
    "    for user in range(length):\n",
    "        authsum=0\n",
    "        for conn in inlink[user]:\n",
    "            authsum=hubs[conn]+authsum\n",
    "        auth[user]=authsum\n",
    "        norm+=authsum**2\n",
    "    for user in range(length):\n",
    "        auth[user]=auth[user]/norm\n",
    "hubs=enumerate(hubs)\n",
    "hubs=sorted(hubs,key=lambda x: x[1],reverse=True)\n",
    "print(\"\\nHub Scores:\\nRank  Name  score\\n\")\n",
    "for rank in range(10):\n",
    "    print('%d %s-%0.2f' % (rank+1,allnames[hubs[rank][0]],hubs[rank][1]))\n",
    "auth=enumerate(auth)\n",
    "auth=sorted(auth,key=lambda x: x[1],reverse=True)\n",
    "print(\"\\nAuthority Scores:\\nRank  Name  score\\n\")\n",
    "for rank in range(10):\n",
    "    print('%d %s-%0.2f' % (rank+1,allnames[auth[rank][0]],auth[rank][1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
